{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -r ./requirements.txt -q\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: langchain\n",
      "Version: 0.0.354\n",
      "Summary: Building applications with LLMs through composability\n",
      "Home-page: https://github.com/langchain-ai/langchain\n",
      "Author: \n",
      "Author-email: \n",
      "License: MIT\n",
      "Location: /Users/sagar/anaconda3/envs/langproj/lib/python3.12/site-packages\n",
      "Requires: aiohttp, dataclasses-json, jsonpatch, langchain-community, langchain-core, langsmith, numpy, pydantic, PyYAML, requests, SQLAlchemy, tenacity\n",
      "Required-by: \n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip show langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: openai\n",
      "Version: 0.28.1\n",
      "Summary: Python client library for the OpenAI API\n",
      "Home-page: https://github.com/openai/openai-python\n",
      "Author: OpenAI\n",
      "Author-email: support@openai.com\n",
      "License: \n",
      "Location: /Users/sagar/anaconda3/envs/langproj/lib/python3.12/site-packages\n",
      "Requires: aiohttp, requests, tqdm\n",
      "Required-by: \n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip show openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv(), override = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_document(file):\n",
    "    from langchain.document_loaders import PyPDFLoader\n",
    "    print(f'Loading {file}')\n",
    "    loader = PyPDFLoader(file)\n",
    "    data = loader.load()\n",
    "    return data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_data(data, chunk_size = 256):\n",
    "    from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size = 256, chunk_overlap = 10)\n",
    "    chunks =text_splitter.split_documents(data)\n",
    "    return chunks\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_or_fetch_embeddings(index_name, chunks):\n",
    "    import pinecone\n",
    "    from pinecone import Pinecone, PodSpec\n",
    "    from langchain.vectorstores import Pinecone as Pineconevs\n",
    "    from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "    pc = Pinecone(api_key = os.environ.get('PINECONE_API_KEY'))\n",
    "\n",
    "    if index_name in pc.list_indexes().names():\n",
    "        print(f'Index {index_name} already exists. Loading embeddings...', end = '')\n",
    "        vector_store = Pineconevs.from_existing_index(index_name, embeddings)\n",
    "        print('ok')\n",
    "        return vector_store\n",
    "    else:\n",
    "        print(f'Creating Index {index_name} and embeddings...', end = '')\n",
    "        pc.create_index(index_name, dimension = 1536, metric = 'cosine', spec=PodSpec(\n",
    "\t\tenvironment='gcp-starter'\n",
    "\t))\n",
    "        vector_store = Pineconevs.from_documents(chunks, embeddings, index_name = index_name)\n",
    "        print('OK')\n",
    "        return vector_store\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_pinecone_index(index_name = 'all'):\n",
    "    import pinecone\n",
    "    from pinecone import Pinecone\n",
    "    pc = Pinecone(api_key=os.environ.get('PINECONE_API_KEY'))\n",
    "    if index_name == 'all':\n",
    "        indexes = pc.list_indexes()\n",
    "        print('Deleting all indices...')\n",
    "        for index in indexes:\n",
    "            pc.delete_index(index)\n",
    "        print('OK')\n",
    "    else:\n",
    "        print(f'Deleting index {index_name}...',end = '')\n",
    "        pc.delete_index(index_name)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading files/Sagar_Tetali_CV.pdf\n",
      "{'source': 'files/Sagar_Tetali_CV.pdf', 'page': 0}\n",
      "You have 2 pages in your data\n"
     ]
    }
   ],
   "source": [
    "data = load_document('files/Sagar_Tetali_CV.pdf')\n",
    "print(data[0].metadata)\n",
    "print(f'You have {len(data)} pages in your data')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_document(vector_store, query):\n",
    "    from langchain.chains import RetrievalQA\n",
    "    from langchain_openai import ChatOpenAI\n",
    "\n",
    "    llm = ChatOpenAI(model = 'gpt-3.5-turbo', temperature = 0)\n",
    "    retriever = vector_store.as_retriever(search_type = 'similarity', search_kwargs = {'k':3})\n",
    "    chain = RetrievalQA.from_chain_type(llm = llm, retriever = retriever, return_source_documents = True)\n",
    "    answer = chain.invoke({'query': query})\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_embedding_cost(texts):\n",
    "    import tiktoken\n",
    "    enc = tiktoken.encoding_for_model('text-embedding-ada-002')\n",
    "    total_tokens = sum([len(enc.encode(page.page_content)) for page in texts])\n",
    "    print(f'Total Tokens: {total_tokens}')\n",
    "    print(f'Embedding Cost in USD: {total_tokens/ 1000 * 0.0004:.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      ", RNNs, LSTMS, and data augmentation.  Experience Machine Learning Engineer |  September 2019 - March 2020 BigLittle Innovations Bengaluru, India  Built modules that extract a company’s real-time business processes from event logs, check conformance\n",
      "Total Tokens: 944\n",
      "Embedding Cost in USD: 0.000378\n"
     ]
    }
   ],
   "source": [
    "chunks = chunk_data(data)\n",
    "print(len(chunks))\n",
    "print(chunks[10].page_content)\n",
    "print_embedding_cost(chunks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting index askadocument...Creating Index askadocument and embeddings...OK\n"
     ]
    }
   ],
   "source": [
    "delete_pinecone_index('askadocument')\n",
    "index_name = 'askadocument'\n",
    "vector_store = insert_or_fetch_embeddings(index_name, chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<langchain_community.vectorstores.pinecone.Pinecone object at 0x1160deb10>\n"
     ]
    }
   ],
   "source": [
    "print(vector_store)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'indexes': [{'dimension': 1536,\n",
      "              'host': 'askadocument-293s6kc.svc.gcp-starter.pinecone.io',\n",
      "              'metric': 'cosine',\n",
      "              'name': 'askadocument',\n",
      "              'spec': {'pod': {'environment': 'gcp-starter',\n",
      "                               'pod_type': 'starter',\n",
      "                               'pods': 1,\n",
      "                               'replicas': 1,\n",
      "                               'shards': 1}},\n",
      "              'status': {'ready': True, 'state': 'Ready'}}]}\n"
     ]
    }
   ],
   "source": [
    "indexes = pc.list_indexes()\n",
    "print(indexes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting index askadocument..."
     ]
    }
   ],
   "source": [
    "delete_pinecone_index(index_name = 'askadocument')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: pinecone-client\n",
      "Version: 3.0.0\n",
      "Summary: Pinecone client and SDK\n",
      "Home-page: https://www.pinecone.io\n",
      "Author: Pinecone Systems, Inc.\n",
      "Author-email: support@pinecone.io\n",
      "License: Apache-2.0\n",
      "Location: /Users/sagar/anaconda3/envs/langproj/lib/python3.12/site-packages\n",
      "Requires: certifi, tqdm, typing-extensions, urllib3\n",
      "Required-by: \n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip show pinecone-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query': 'where did this person study?', 'result': 'This person studied at the University of Pennsylvania in Philadelphia, PA, USA for their Masters in Engineering (MSE) in Computer Graphics and Game Technology. They also studied at GITAM University in Visakhapatnam, Andhra Pradesh, India for their Bachelor of Technology.', 'source_documents': [Document(page_content='Education University of Pennsylvania, Philadelphia, PA, USA, |  2017- 2019 Masters in Engineering (MSE), Computer Graphics and Game Technology GPA: 3.61/4.00 GITAM University, Visakhapatnam, Andhra Pradesh, India |  2012 - 2016 Bachelor of Technology', metadata={'page': 0.0, 'source': 'files/Sagar_Tetali_CV.pdf'}), Document(page_content='and an MSE in Computer Graphics and Game technology from the University of Pennsylvania. After a stint as a freelance tech writer and media professional over the pandemic years, I’m looking for developer roles, preferably with an ML focus. Education', metadata={'page': 0.0, 'source': 'files/Sagar_Tetali_CV.pdf'}), Document(page_content='Researcher |  April 2020 - Current Film Companion, The Indian Express Analytical essays and podcasts on Indian cinema, exploring ﬁlm, culture, and philosophy. Researcher on a documentary on SS Rajamouli. Jury member for FC Gold. Skills Languages: Python,', metadata={'page': 1.0, 'source': 'files/Sagar_Tetali_CV.pdf'})]}\n"
     ]
    }
   ],
   "source": [
    "answer = ask_document(vector_store, \"where did this person study?\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langproj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
